{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import mariadb\n",
    "import os\n",
    "from datetime import datetime\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTypes(df,targetCols,renameCols=False):\n",
    "    \"\"\"\n",
    "    Objetivo: Función que permite retirar registros no numéricos en la columnas especificadas\n",
    "    Entradas:\n",
    "        *type df: pandas.DataFrame\n",
    "        *df:Dataframe a limpiar\n",
    "        \n",
    "        *type targetCols: list(string)\n",
    "        *targetCols: Columnas a retirar registros no numéricos\n",
    "        \n",
    "        *type renameCols: list(string)\n",
    "        *renameCols: Permite renombrar las columnas que se limpiaron\n",
    "    \n",
    "    Salidas:\n",
    "        *type nanRows: pandas.DataFrame\n",
    "        *nanRows: Dataframe con registros no numéricos\n",
    "\n",
    "        *type dfCleaned: pandas.DataFrame\n",
    "        *dfCleaned: Dataframe sin los registros numéricos\n",
    "    \"\"\"\n",
    "    newDf=df.copy()\n",
    "    dummyPrefix=\"dummy_\"\n",
    "    for col in targetCols:\n",
    "        newDf[dummyPrefix+col]=pd.to_numeric(df[col],errors=\"coerce\")\n",
    "    dfNulls=newDf.isnull()\n",
    "    dummyNames=[dummyPrefix+k for k in targetCols]\n",
    "    nanFilters=' | '.join(['{}=={}'.format(k, True) for k in dummyNames ])\n",
    "    nanRows=newDf[dfNulls.eval(nanFilters)].drop(columns=dummyNames)\n",
    "    nanRows=nanRows.assign(status= lambda x:\"error\")\n",
    "    nanRows=nanRows.assign(message= lambda x:\"Data type error\")\n",
    "    goodFilters=' | '.join(['{}!={}'.format(k, True) for k in dummyNames ])\n",
    "    dfCleaned=newDf[dfNulls.eval(goodFilters)].drop(columns=dummyNames)\n",
    "    if renameCols!=False:\n",
    "        newNames={k:v for k,v in zip(targetCols,renameCols) }\n",
    "        nanRows.rename(columns=newNames,inplace=True)\n",
    "        dfCleaned.rename(columns=newNames,inplace=True)\n",
    "\n",
    "    return dfCleaned,nanRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createJsonGeo(df,newCol,rootJson=\"root\",limit=1):\n",
    "    \"\"\"\n",
    "    Objetivo: Función que genera un Json de Geolocations para consumir la api \n",
    "                https://api.postcodes.io/postcodes\n",
    "    Entradas:\n",
    "        *type df: pandas.DataFrame\n",
    "        *df: Dataframe que contiene los registros a transformar en Json\n",
    "\n",
    "        *type newCol: string\n",
    "        *newCol: Nombre de la nueva columna a crear\n",
    "\n",
    "        *type rootJson: string\n",
    "        *rootJson: Raíz del json nuevo a crear\n",
    "\n",
    "        *type limit: int\n",
    "        *limit: Escalar para la nueva columna que se creará \n",
    "    Salidas:\n",
    "        *type Json: string (JSON)\n",
    "        *dfJson: Json que contiene la estructura necesaria para consumir la API\n",
    "    \"\"\"\n",
    "    newDf=df.copy()\n",
    "    newDf[newCol]=(np.ones((newDf.shape[0],1),dtype=int))*limit\n",
    "    dictRows=newDf.to_dict(orient=\"records\")\n",
    "    dfJson=json.dumps({rootJson:dictRows})\n",
    "    return dfJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPostCodes(url,data,headers,rawData,maxRetry=3):\n",
    "    \"\"\"\n",
    "    Objetivo: Función que consume una la api https://api.postcodes.io/postcodes y devuelve\n",
    "    un dataframe con los coordenadas, el estado de la petición y su respectivo código postal\n",
    "    Entradas:\n",
    "        *type url: string\n",
    "        *url: Url de la API a consumir\n",
    "\n",
    "        *type data: string (JSON)\n",
    "        *data:    Json con que se va a enviar a la API\n",
    "\n",
    "        *type headers: dictionary\n",
    "        *headers: Headers de la petición\n",
    "\n",
    "        *type rawData: pandas.DataFrame\n",
    "        *rawData: Dataframe que cotiene todas las coordenadas antes de ser procesadas transformadas en JSON\n",
    "\n",
    "        *type maxRetry: int\n",
    "        *maxRetry: Número máximo de reintentos \n",
    "    Salidas:\n",
    "        *type dfresults: pandas.DataFrame\n",
    "        *dfresults: Dataframe que contiene las coordenas y sus respectivos códigos postales. Solo se retorna si\n",
    "                la petición tiene un estado de respuesta 200.\n",
    "        \n",
    "        *type arrayError: pandas.DataFrame\n",
    "        *arrayError: Dataframe que contiene las coordenadas pero con status de error. Solo se retorna si la \n",
    "                petición tiene un estado de respuesta diferente a 200.      \n",
    "    \"\"\"\n",
    "    http = requests.Session()  \n",
    "    retry_strategy = Retry(\n",
    "    connect=maxRetry,\n",
    "    other=maxRetry,\n",
    "    status=maxRetry,\n",
    "    status_forcelist=[501,502,503],\n",
    "    allowed_methods=[\"POST\"],\n",
    "    backoff_factor=0.3\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    http.mount(\"https://\",adapter)\n",
    "    try:\n",
    "        response=http.post(url=url,data=data,headers=headers)\n",
    "    except urllib3.exceptions.MaxRetryError as e:\n",
    "        raise Exception(e)\n",
    "    \n",
    "    responseJson=response.json()\n",
    "    if responseJson[\"status\"]==200:\n",
    "        resultsArray=[]\n",
    "        for apiResults in responseJson[\"result\"]:\n",
    "            resultDictionary={}\n",
    "            if apiResults[\"result\"]!=None:\n",
    "                resultDictionary[\"longitude\"]=apiResults[\"result\"][0][\"longitude\"]\n",
    "                resultDictionary[\"latitude\"]=apiResults[\"result\"][0][\"latitude\"]\n",
    "                resultDictionary[\"status\"]=\"ok\"\n",
    "                resultDictionary[\"message\"]=apiResults[\"result\"][0][\"postcode\"]\n",
    "            else:\n",
    "                resultDictionary[\"longitude\"]=apiResults[\"query\"][\"longitude\"]\n",
    "                resultDictionary[\"latitude\"]=apiResults[\"query\"][\"latitude\"]\n",
    "                resultDictionary[\"status\"]=\"error\"\n",
    "                resultDictionary[\"message\"]=\"Postcode not found\"\n",
    "            resultsArray.append(resultDictionary)\n",
    "        dfresults=pd.DataFrame(resultsArray)\n",
    "        success=True\n",
    "        return dfresults,success\n",
    "    else:\n",
    "        arrayError=rawData.copy()\n",
    "        arrayError=arrayError.assign(status= lambda x:\"error\")\n",
    "        arrayError=arrayError.assign(message= lambda x:responseJson[\"error\"])\n",
    "        success=False\n",
    "        return arrayError,success\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLogFile(df,path,filename,header=False):\n",
    "    \"\"\"\n",
    "    Objetivo: Función que escribe en un archivo csv los registros de dataframe especificado\n",
    "    Entradas:\n",
    "        *type df: pandas.DataFrame\n",
    "        *df: Dataframe que contiene los registros a escribir\n",
    "\n",
    "        *type path: string\n",
    "        *path: Ruta del directorio del archivo de salida\n",
    "        \n",
    "        *type filename: string\n",
    "        *filename: Nombre del archivo de salida sin extensión\n",
    "        \n",
    "        *type header: boolean\n",
    "        *header: Si es True escribe los titulos del dataframe en caso contrario no.     \n",
    "    \"\"\"\n",
    "    output=open(os.path.join(path,filename),\"a\")\n",
    "    output.write(df.to_csv(index=False,line_terminator='\\n',header=header))\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Esta clase está diseñada para concetarse a la base de datos ukpostcodes\n",
    "y con sus diferentes métodos poder extraer o insertar datos en la tabla\n",
    "coordinates_postcodes\n",
    "\"\"\"\n",
    "\n",
    "class coordinatesPostcodes:\n",
    "    conn=''\n",
    "    def connectDb(self,user,password,uri,database,port=3306):\n",
    "        \"\"\"\n",
    "        Objetivo: Conectase a la base de datos\n",
    "        Entradas:\n",
    "            *type self: coordinatesPostcodes\n",
    "            *self: Atributos de la clase como 'conn'\n",
    "\n",
    "            *type user: string \n",
    "            *user:     Usuario de la base de datos\n",
    "            \n",
    "            *type password: string\n",
    "            *password: Contraseña de la base de datos\n",
    "            \n",
    "            *type uri: string\n",
    "            *uri: Host donde esta la base de datos\n",
    "            \n",
    "            *type database: string\n",
    "            *database: Nombre de la base de datos\n",
    "            \n",
    "            *type port: int\n",
    "            *port:     Puerto de conexión a la base de datos\n",
    "        Salida:            \n",
    "            *type success: boolean\n",
    "            *success:   Si la conexión fue exitosa retorna True en caso contrario False\n",
    "            \n",
    "            *type message: string\n",
    "            *message:   Si la conexión fue fallida contiene el mensaje de error en caso contrario esta vacio\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.conn = mariadb.connect(\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=uri,\n",
    "            port=port,\n",
    "            database=database\n",
    "            )\n",
    "            success=True\n",
    "            message=\"\"\n",
    "        except mariadb.Error as e:\n",
    "            self.conn=''\n",
    "            success=False\n",
    "            message=e\n",
    "        return success,message\n",
    "    \n",
    "    def insertPostcode(self,values):\n",
    "\n",
    "        \"\"\" \n",
    "        Objetivo: Insertar en la tabla coordenates_postcodes los nuevos postcocdes. Si ya existe postcode\n",
    "        para la latitud y longitud especificada, se actualiza.\n",
    "        Entradas:\n",
    "            *type values: tuple\n",
    "            *values: Tupla que contiene los valores de longitud, latitud y postcode a insertar en la base de \n",
    "            datos\n",
    "        Salidas:\n",
    "            *type success: boolean\n",
    "            *success: Si la inserción fue exitosa retorna True en caso contrario retorna False.\n",
    "\n",
    "            *type message: string\n",
    "            *message: Si la inserción no fue exitosa retorna mensaje de error en caso contrario \n",
    "            retorna vacio.\n",
    "        \n",
    "        \"\"\"\n",
    "        cur=self.conn.cursor()\n",
    "        try:\n",
    "            cur.execute(\n",
    "            \"INSERT INTO coordenates_postcodes (latitude,longitude,postcode) VALUES (?,?,?) ON DUPLICATE KEY UPDATE postcode= ? \"\n",
    "            , values )\n",
    "            success=True\n",
    "            message=''\n",
    "            return success,message\n",
    "        except mariadb.Error as e:\n",
    "            success=False\n",
    "            message=e\n",
    "            return success,message\n",
    "            \n",
    "    def closeConnection(self):\n",
    "        \"\"\" \n",
    "        Objetivo: Cerrar la conexión de la base de datos\n",
    "        \"\"\"\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=\"https://api.postcodes.io/postcodes\"\n",
    "HEADERS={\"Content-Type\":\"application/json\"}\n",
    "TARGET_COLUMNS=[\"lat\",\"lon\"]\n",
    "COLUMNS_RENAME=[\"latitude\",\"longitude\"]\n",
    "CHUNKSIZE=100\n",
    "NEWCOL=\"limit\"\n",
    "ROOT_JSON=\"geolocations\"\n",
    "INPUT_DATA_FILE=r\"..\\data\\postcodesgeo2.csv\"\n",
    "OUTPUT_LOG_DIR=r\"..\\logs\"\n",
    "OUTPUT_LOG_FILENAME=\"log.csv\"\n",
    "OUTPUT_INSERTED_RECORDS_DIR=r\"..\\logs\"\n",
    "OUTPUT_INSERTED_RECORDS_FILE=\"inserted_records.csv\"\n",
    "DB_USER=\"user\"\n",
    "DB_PASSWORD=\"password\"\n",
    "DB_NAME=\"ukpostcodes\"\n",
    "DB_URI=\"localhost\"\n",
    "INSERTED_FLAG=True\n",
    "LOG_FLAG=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentTime=(datetime.now()).strftime(\"%Y_%m_%d-%H_%M_%S_%p\")\n",
    "\n",
    "if CHUNKSIZE>100:\n",
    "    raise Exception(\"chunkSize no puede ser mayor a 100\")\n",
    "\n",
    "for chunk in pd.read_csv(INPUT_DATA_FILE,chunksize=CHUNKSIZE):\n",
    "    dfCleaned,nanRows=cleanTypes(chunk,TARGET_COLUMNS,COLUMNS_RENAME)\n",
    "    if dfCleaned.shape[0]>=1:\n",
    "        dfJson=createJsonGeo(dfCleaned,NEWCOL,ROOT_JSON)\n",
    "        dfProcesed,postCodesSuccess=getPostCodes(url=URL,data=dfJson,headers=HEADERS,rawData=dfCleaned)\n",
    "        if postCodesSuccess==True:\n",
    "            coordinatesPostcodesObject=coordinatesPostcodes()\n",
    "            connSuccess,connMessage=coordinatesPostcodesObject.connectDb(DB_USER,DB_PASSWORD,DB_URI,DB_NAME)\n",
    "            if connSuccess==False:\n",
    "                raise Exception(connMessage)\n",
    "            insertedRecordsArray=[]\n",
    "            for record in dfProcesed.values:\n",
    "                if record[2]!=\"error\":\n",
    "                    insertSuccess,insertMessage=coordinatesPostcodesObject.insertPostcode(\n",
    "                        (record[1],record[0],record[3],record[3]))\n",
    "                    if insertSuccess==False:\n",
    "                        record[2]=\"error\"\n",
    "                        record[3]=insertMessage\n",
    "                insertedRecordsArray.append(record)    \n",
    "            coordinatesPostcodesObject.closeConnection()\n",
    "            dfInsertedRecords=pd.DataFrame(data=insertedRecordsArray,columns=dfProcesed.columns.values)\n",
    "            allProcesedRecords=pd.concat([dfInsertedRecords,nanRows],ignore_index=True)\n",
    "            \n",
    "            if INSERTED_FLAG==True:\n",
    "                titlesInserted=True\n",
    "                INSERTED_FLAG=False\n",
    "            else:\n",
    "                titlesInserted=False\n",
    "            generateLogFile(dfInsertedRecords[dfInsertedRecords[\"status\"]==\"ok\"],\n",
    "            OUTPUT_INSERTED_RECORDS_DIR,\n",
    "            filename=currentTime+\"_\"+OUTPUT_INSERTED_RECORDS_FILE,\n",
    "            header=titlesInserted)\n",
    "        else:\n",
    "            allProcesedRecords=pd.concat([dfProcesed,nanRows],ignore_index=True)\n",
    "    else:\n",
    "        allProcesedRecords=nanRows.copy()\n",
    "    if LOG_FLAG==True:\n",
    "        titles=True\n",
    "        LOG_FLAG=False\n",
    "    else:\n",
    "        titles=False\n",
    "    generateLogFile(allProcesedRecords,\n",
    "    OUTPUT_LOG_DIR,\n",
    "    filename=currentTime+\"_\"+OUTPUT_LOG_FILENAME,\n",
    "    header=titles)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a242c5d6ffe527feed3227becc6d8ea4d8415c6e1dc2411e542514a43006c348"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('Udemy_ML': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
